---
---

@article{ghosh2020,
	author={Ghosh, Tilottama  and Coscieme, Luca  and Anderson, Sharolyn J.  and Sutton, Paul C. },
	title={Building Volume Per Capita (BVPC): A Spatially Explicit Measure of Inequality Relevant to the SDGs},
	journal={Frontiers in Sustainable Cities},
	volume={2},
	year={2020},
	url={https://www.frontiersin.org/journals/sustainable-cities/articles/10.3389/frsc.2020.00037},
	doi={10.3389/frsc.2020.00037},
	issn={2624-9634},
	abstract={<p>Building Volume Per Capita (BVPC - cubic meters of building per person) is presented as a proxy measure of economic inequality and a direct measure of housing inequality. Sustainable development goal 10 (SDG 10: reduced inequalities) is synergic for achieving SDG 11 on sustainable cities and communities. Access to safe and affordable housing, transport systems, and public spaces are some of the targets of SDG 11 that mostly link with reducing inequalities. The Habitat III New Urban Agenda sets equal access to urban spaces, infrastructures and basic services as crucial for developing sustainable cities. Earth Observation (EO) data including remotely sensed satellite data, airborne data, and model outputs, in combination with demographic, and other statistical data, have been gaining importance for monitoring progress of the SDGs. High spatial resolution building footprint data derived from aerial photographs, stereo imagery, and LIDAR data, obtained for the cities of California, between 2010 and 2015, were used in this study. These measures of building volume were rasterized and juxtaposed with (divided by) a variety of demographic data including vector-based census data of 2015 and LandScan raster data of population counts of 2015. The National Landcover dataset of 2011 was used to characterize the land cover variability of the cities. Using these datasets, the spatial pattern and distribution of BVPC for nine cities in California were studied. The results showed that BVPC was inversely related with intensity of development, and positively related with median household income within cities. A BV-GINI was also developed to characterize the variability of the BVPC at the census tract level and the pixel level. This measure of income inequality, housing and population density is objective and easily executable. It can be used in other cities and countries and may help overcome lack of data in SDG indicators.</p>}
}
@misc{osm2024,
   author = {{OpenStreetMap contributors}},
   title = {{OpenStreetMap Foundation}},
   howpublished = {Available as open data under the Open Data Commons Open Database License (ODbL) at \url{ https://www.openstreetmap.org}},
   year = {2023},
   note = {Accessed: 2024-07-17}
 }
 @article{ledoux2021,
  author = {Ledoux, Hugo and Biljecki, Filip and Dukai, Balázs and Kumar, Kavisha and Peters, Ravi and Stoter, Jantien and Commandeur, Tom},
  doi = {10.21105/joss.02866},
  journal = {Journal of Open Source Software},
  number = {57},
  pages = {2866},
  title = {3dfier: automatic reconstruction of 3D city models},
  volume = {6},
  year = {2021}
}
@article{Gran2021,
   abstract = {Project Jupyter is an open-source project for interactive computing widely used in data science, machine learning, and scientific computing. We argue that even though Jupyter helps users perform complex, technical work, Jupyter itself solves problems that are fundamentally human in nature. Namely, Jupyter helps humans to think and tell stories with code and data. We illustrate this by describing three dimensions of Jupyter: 1) interactive computing; 2) computational narratives; and 3) the idea that Jupyter is more than software. We illustrate the impact of these dimensions on a community of practice in earth and climate science.},
   author = {Brian E. Granger and Fernando Perez},
   doi = {10.1109/MCSE.2021.3059263},
   issn = {1558366X},
   issue = {2},
   journal = {Computing in Science and Engineering},
   month = {3},
   pages = {7-14},
   publisher = {IEEE Computer Society},
   title = {Jupyter: Thinking and Storytelling with Code and Data},
   volume = {23},
   year = {2021},
}
@misc{UN2012b,
   author = {{United Nations. Department of Economic and Social Affairs}},
   title = {{Sustainable Development. Goal 11}},
   howpublished = {\url{https://sdgs.un.org/goals/goal11}},
   year = {2012},
}
%
@inproceedings{holdgraf_evidence_2014,
	address = {Brisbane, Australia, Australia},
	title = {Evidence for {Predictive} {Coding} in {Human} {Auditory} {Cortex}},
	booktitle = {International {Conference} on {Cognitive} {Neuroscience}},
	publisher = {Frontiers in Neuroscience},
	author = {Holdgraf, Christopher Ramsay and de Heer, Wendy and Pasley, Brian N. and Knight, Robert T.},
	year = {2014}
}

@article{holdgraf_rapid_2016,
	title = {Rapid tuning shifts in human auditory cortex enhance speech intelligibility},
	volume = {7},
	issn = {2041-1723},
	url = {http://www.nature.com/doifinder/10.1038/ncomms13654},
	doi = {10.1038/ncomms13654},
	number = {May},
	journal = {Nature Communications},
	author = {Holdgraf, Christopher Ramsay and de Heer, Wendy and Pasley, Brian N. and Rieger, Jochem W. and Crone, Nathan and Lin, Jack J. and Knight, Robert T. and Theunissen, Frédéric E.},
	year = {2016},
	pages = {13654},
	file = {Holdgraf et al. - 2016 - Rapid tuning shifts in human auditory cortex enhance speech intelligibility.pdf:C\:\\Users\\chold\\Zotero\\storage\\MDQP3JWE\\Holdgraf et al. - 2016 - Rapid tuning shifts in human auditory cortex enhance speech intelligibility.pdf:application/pdf}
}

@inproceedings{holdgraf_portable_2017,
	title = {Portable learning environments for hands-on computational instruction using container-and cloud-based technology to teach data science},
	volume = {Part F1287},
	isbn = {978-1-4503-5272-7},
	doi = {10.1145/3093338.3093370},
	abstract = {© 2017 ACM. There is an increasing interest in learning outside of the traditional classroom setting. This is especially true for topics covering computational tools and data science, as both are challenging to incorporate in the standard curriculum. These atypical learning environments offer new opportunities for teaching, particularly when it comes to combining conceptual knowledge with hands-on experience/expertise with methods and skills. Advances in cloud computing and containerized environments provide an attractive opportunity to improve the effciency and ease with which students can learn. This manuscript details recent advances towards using commonly-Available cloud computing services and advanced cyberinfrastructure support for improving the learning experience in bootcamp-style events. We cover the benets (and challenges) of using a server hosted remotely instead of relying on student laptops, discuss the technology that was used in order to make this possible, and give suggestions for how others could implement and improve upon this model for pedagogy and reproducibility.},
	booktitle = {{ACM} {International} {Conference} {Proceeding} {Series}},
	author = {Holdgraf, Christopher Ramsay and Culich, A. and Rokem, A. and Deniz, F. and Alegro, M. and Ushizima, D.},
	year = {2017},
	keywords = {Teaching, Bootcamps, Cloud computing, Data science, Docker, Pedagogy}
}

@article{holdgraf_encoding_2017,
	title = {Encoding and decoding models in cognitive electrophysiology},
	volume = {11},
	issn = {16625137},
	doi = {10.3389/fnsys.2017.00061},
	abstract = {© 2017 Holdgraf, Rieger, Micheli, Martin, Knight and Theunissen. Cognitive neuroscience has seen rapid growth in the size and complexity of data recorded from the human brain as well as in the computational tools available to analyze this data. This data explosion has resulted in an increased use of multivariate, model-based methods for asking neuroscience questions, allowing scientists to investigate multiple hypotheses with a single dataset, to use complex, time-varying stimuli, and to study the human brain under more naturalistic conditions. These tools come in the form of “Encoding” models, in which stimulus features are used to model brain activity, and “Decoding” models, in which neural features are used to generated a stimulus output. Here we review the current state of encoding and decoding models in cognitive electrophysiology and provide a practical guide toward conducting experiments and analyses in this emerging field. Our examples focus on using linear models in the study of human language and audition. We show how to calculate auditory receptive fields from natural sounds as well as how to decode neural recordings to predict speech. The paper aims to be a useful tutorial to these approaches, and a practical introduction to using machine learning and applied statistics to build models of neural activity. The data analytic approaches we discuss may also be applied to other sensory modalities, motor systems, and cognitive systems, and we cover some examples in these areas. In addition, a collection of Jupyter notebooks is publicly available as a complement to the material covered in this paper, providing code examples and tutorials for predictive modeling in python. The aimis to provide a practical understanding of predictivemodeling of human brain data and to propose best-practices in conducting these analyses.},
	journal = {Frontiers in Systems Neuroscience},
	author = {Holdgraf, Christopher Ramsay and Rieger, J.W. and Micheli, C. and Martin, S. and Knight, R.T. and Theunissen, F.E.},
	year = {2017},
	keywords = {Decoding models, Encoding models, Electrocorticography (ECoG), Electrophysiology/evoked potentials, Machine learning applied to neuroscience, Natural stimuli, Predictive modeling, Tutorials}
}

@book{ruby,
  title     = {The Ruby Programming Language},
  author    = {Flanagan, David and Matsumoto, Yukihiro},
  year      = {2008},
  publisher = {O'Reilly Media}
}
